{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import copy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(PATH):\n",
    "    X_dataset = {}\n",
    "    Y_dataset = {}\n",
    "    for path, dirs, files in os.walk(PATH):\n",
    "        for filename in files:\n",
    "            fullpath = os.path.join(path, filename)\n",
    "            if \"both\" not in fullpath:\n",
    "                with open(fullpath, 'r', encoding=\"utf8\") as file:\n",
    "                    X_dataset, Y_dataset = add_file_to_dataset(fullpath, X_dataset, Y_dataset, file.read())\n",
    "\n",
    "    return X_dataset, Y_dataset       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_file_to_dataset(fullpath, x_dataset, y_dataset, file):\n",
    "    article = extract_article(fullpath)\n",
    "    file = preprocess(file)\n",
    "    if article not in x_dataset.keys() :\n",
    "        x_dataset[article] = []\n",
    "        y_dataset[article] = []\n",
    "    x_dataset[article] = x_dataset[article] + [file]\n",
    "    label = 0 if \"non-violation\" in fullpath else 1\n",
    "    y_dataset[article] = y_dataset[article] + [label]\n",
    "    return x_dataset, y_dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article(path): \n",
    "    pattern = r\"(Article\\d+)\"\n",
    "    result = re.search(pattern, path)\n",
    "    article = result.group(1)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file): \n",
    "    file = extract_paragraphs(file)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paragraphs(file): \n",
    "    pat = r'((PROCEDURE|procedure\\n|THE FACTS|the facts\\n).+?)(III|THE LAW|the law\\n|PROCEEDINGS|ALLEGED VIOLATION OF ARTICLE)'\n",
    "    result = re.search(pat, file, re.S)\n",
    "    return result.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"Datasets\\\\Human rights dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_docs, Y_train_docs = read_dataset(base_path + \"\\\\train\")\n",
    "#X_extra_test_docs, Y_extra_test = read_dataset(base_path + \"\\\\test_violations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_articles(train_set):\n",
    "    selected_training_set = copy.deepcopy(train_set)\n",
    "    \n",
    "    for key in train_set.keys():\n",
    "        if len(train_set[key]) <= 50:\n",
    "            selected_training_set.pop(key)\n",
    "            continue\n",
    "    return selected_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_docs = select_articles(X_train_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the articles according to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_old = X_train_docs[\"Article2\"] + X_train_docs[\"Article3\"] + X_train_docs[\"Article5\"] + X_train_docs[\"Article6\"] + X_train_docs[\"Article8\"] + X_train_docs[\"Article10\"] + X_train_docs[\"Article11\"] + X_train_docs[\"Article13\"] + X_train_docs[\"Article14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_old = Y_train_docs[\"Article2\"] + Y_train_docs[\"Article3\"] + Y_train_docs[\"Article5\"] + Y_train_docs[\"Article6\"] + Y_train_docs[\"Article8\"] + Y_train_docs[\"Article10\"] + Y_train_docs[\"Article11\"] + Y_train_docs[\"Article13\"] + Y_train_docs[\"Article14\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new pre-processing removes escape sequences which are nonprintable characters and add nothing to the text. It also contains more detail for what paragraphs should match, making Summary and Table of Content paragraphs not match anymore. It also ignores case because some paragraph titles may be written in lowercase or there might be typos (e.g. \"pROCEEDINGS\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(PATH):\n",
    "    X_dataset = {}\n",
    "    Y_dataset = {}\n",
    "    for path, dirs, files in os.walk(PATH):\n",
    "        for filename in files:\n",
    "            fullpath = os.path.join(path, filename)\n",
    "            if \"both\" not in fullpath:\n",
    "                with open(fullpath, 'r', encoding=\"utf8\") as file:\n",
    "                    X_dataset, Y_dataset = add_file_to_dataset(fullpath, X_dataset, Y_dataset, file.read())\n",
    "\n",
    "    return X_dataset, Y_dataset       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_file_to_dataset(fullpath, x_dataset, y_dataset, file):\n",
    "    article = extract_article(fullpath)\n",
    "    file = preprocess(file)\n",
    "    if article not in x_dataset.keys() :\n",
    "        x_dataset[article] = []\n",
    "        y_dataset[article] = []\n",
    "    x_dataset[article] = x_dataset[article] + [file]\n",
    "    label = 0 if \"non-violation\" in fullpath else 1\n",
    "    y_dataset[article] = y_dataset[article] + [label]\n",
    "    return x_dataset, y_dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article(path): \n",
    "    pattern = r\"(Article\\d+)\"\n",
    "    result = re.search(pattern, path)\n",
    "    article = result.group(1)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file): \n",
    "    file = extract_paragraphs(file)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paragraphs(file): \n",
    "    file = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff]', '', file)\n",
    "    pat = r'(PROCEDURE\\s*\\n.+?)?((THE CIRCUMSTANCES OF THE CASE\\s*\\n.+?RELEVANT DOMESTIC LAW.+?)|(\\n(AS TO THE FACTS|THE FACTS)\\s*\\n.+?))(\\nIII\\.|THE LAW\\s*\\n|PROCEEDINGS BEFORE THE COMMISSION\\s*\\n|ALLEGED VIOLATION OF ARTICLE [0-9]+ OF THE CONVENTION \\s*\\n)'\n",
    "    result = re.search(pat, file, re.S |  re.IGNORECASE)\n",
    "    if result is None:\n",
    "        print(repr(file))\n",
    "    content = \"\"\n",
    "    if result.group(1) is not None:\n",
    "        content += result.group(1)\n",
    "    content += result.group(2)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"Datasets\\\\Human rights dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_docs, Y_train_docs = read_dataset(base_path + \"\\\\train\")\n",
    "#X_extra_test_docs, Y_extra_test = read_dataset(base_path + \"\\\\test_violations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_articles(train_set):\n",
    "    selected_training_set = copy.deepcopy(train_set)\n",
    "    \n",
    "    for key in train_set.keys():\n",
    "        if len(train_set[key]) <= 50:\n",
    "            selected_training_set.pop(key)\n",
    "            continue\n",
    "    return selected_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_docs = select_articles(X_train_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the articles according to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train_docs[\"Article2\"] + X_train_docs[\"Article3\"] + X_train_docs[\"Article5\"] + X_train_docs[\"Article6\"] + X_train_docs[\"Article8\"] + X_train_docs[\"Article10\"] + X_train_docs[\"Article11\"] + X_train_docs[\"Article13\"] + X_train_docs[\"Article14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_new = Y_train_docs[\"Article2\"] + Y_train_docs[\"Article3\"] + Y_train_docs[\"Article5\"] + Y_train_docs[\"Article6\"] + Y_train_docs[\"Article8\"] + Y_train_docs[\"Article10\"] + Y_train_docs[\"Article11\"] + Y_train_docs[\"Article13\"] + Y_train_docs[\"Article14\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files changed: 3127\n"
     ]
    }
   ],
   "source": [
    "no = 0\n",
    "for i in range(len(X_train_old)):\n",
    "    if X_train_old[i] != X_train_new[i]:\n",
    "        no += 1\n",
    "print(\"Number of files changed: \" + str(no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
